# 한국금거래소 금 시세 크롤러

한국금거래소(https://www.koreagoldx.co.kr/price/gold)에서 금 시세 데이터를 자동으로 수집하여 엑셀 파일로 저장하는 Python 크롤러입니다.

## 기능

- 한국금거래소 웹사이트에서 실시간 금 시세 데이터 수집
- 순금, 18K, 14K 금 가격 정보 추출
- 페이지네이션을 통한 대량 데이터 수집 (기본 100개)
- 엑셀 파일로 데이터 저장 및 정리
- **상세한 통계 분석 및 시각화**
  - 기본 통계 (평균, 최고가, 최저가, 변동폭, 변동계수)
  - 가격 변동 분석 (일일 변동률, 상승/하락 일수)
  - 기간별 분석 (전체기간, 최근30일, 최근7일)
  - 상관관계 분석 (각 금 종류 간 상관계수)
  - 요약 테이블 (주요 통계값 정리)

## 수집되는 데이터

- **고시날짜**: 금 시세 고시 날짜
- **내가살때_순금(3.75g)**: 순금 구매 가격 (3.75g 기준)
- **내가팔때_순금(3.75g)**: 순금 판매 가격 (3.75g 기준)
- **내가팔때_18K(3.75g)**: 18K 금 판매 가격 (3.75g 기준)
- **내가팔때_14K(3.75g)**: 14K 금 판매 가격 (3.75g 기준)

## 설치 및 실행

### 1. 필요한 라이브러리 설치

```bash
pip install -r requirements.txt
```

### 2. 크롤러 실행

```bash
python3 gold_crawler.py
```

### 3. 통계 분석 실행

```bash
python3 statistics_analyzer.py
```

### 4. 시각화 생성

```bash
python3 visualization_generator.py
```

### 5. 결과 확인

- `gold_prices.xlsx`: 원본 크롤링 데이터
- `gold_prices_with_statistics.xlsx`: 통계 분석이 포함된 종합 데이터
- `visualizations/`: 다양한 차트 이미지 파일들 (PNG)

## 주요 특징

- **Selenium WebDriver**: 동적 웹페이지 처리
- **자동 페이지네이션**: 여러 페이지를 자동으로 탐색하여 데이터 수집
- **데이터 검증**: 유효하지 않은 데이터 필터링
- **엑셀 최적화**: 컬럼 너비 자동 조정 및 날짜 정렬
- **로깅**: 상세한 실행 로그 제공
- **통계 분석**: 종합적인 금 가격 분석 및 시각화
- **다중 시트**: 원본 데이터와 통계 분석을 별도 시트로 구분
- **다양한 시각화**: 7가지 차트로 데이터를 직관적으로 표현
- **고해상도 이미지**: 300 DPI PNG 파일로 고품질 출력

## 생성되는 엑셀 파일 구조

### gold_prices_with_statistics.xlsx
- **원본데이터**: 크롤링된 원본 금 시세 데이터
- **기본통계**: 평균, 중앙값, 최고가, 최저가, 표준편차, 변동계수, 범위
- **가격변동분석**: 일일 변동률, 최대상승/하락률, 상승/하락/보합 일수
- **기간별분석**: 전체기간, 최근30일, 최근7일별 통계
- **상관관계분석**: 각 금 종류 간 상관계수
- **요약테이블**: 주요 통계값을 한눈에 볼 수 있는 요약 테이블

## 생성되는 시각화 파일

### visualizations/ 디렉토리
- **01_price_trends.png**: 금 가격 추이 시계열 차트 (4개 금 종류별)
- **02_price_distribution.png**: 금 가격 분포 히스토그램 (평균, 중앙값 표시)
- **03_correlation_heatmap.png**: 금 종류 간 상관관계 히트맵
- **04_price_changes.png**: 일일 가격 변동률 분석 (통계 정보 포함)
- **05_period_comparison.png**: 기간별 평균 가격 비교 (전체/30일/7일)
- **06_box_plots.png**: 금 종류별 가격 분포 박스플롯
- **07_dashboard.png**: 통합 대시보드 (6개 차트 + 통계 요약)

## 설정 옵션

`gold_crawler.py` 파일의 `main()` 함수에서 수집할 데이터 개수를 조정할 수 있습니다:

```python
success = crawler.run(target_count=100)  # 100개 데이터 수집
```

## 주의사항

- 웹사이트의 구조가 변경될 경우 크롤러 수정이 필요할 수 있습니다
- 과도한 요청으로 인한 IP 차단을 방지하기 위해 적절한 대기 시간이 설정되어 있습니다
- Chrome 브라우저가 설치되어 있어야 합니다 (WebDriver 자동 설치)

## 라이선스

이 프로젝트는 교육 및 개인적 용도로만 사용하시기 바랍니다.
